{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate speech classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hate speech classification baseline using sklearn\n",
    "Dataset: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"don.tuggener@zhaw.ch\"\n",
    "\n",
    "import csv\n",
    "import pdb\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import nltk\n",
    "import os.path\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "#nltk.download('stopwords')\n",
    "STOPWORDS = stopwords.words('english')\n",
    "STEMMER = SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(remove_stopwords=True, remove_numbers=True, do_stem=True, reprocess=False):\n",
    "    \"\"\"\n",
    "    Read CSV with annotated data.\n",
    "    We'll binarize the classification, i.e. subsume all hate speach related classes\n",
    "    'toxic, severe_toxic, obscene, threat, insult, identity_hate'\n",
    "    into one.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isfile('Y.pkl') or not os.path.isfile('X.pkl'):\n",
    "        reprocess = True\n",
    "\n",
    "    if reprocess:\n",
    "        print('unzipping training data...')\n",
    "        zip_ref = zipfile.ZipFile('train.csv.zip', 'r')\n",
    "        zip_ref.extractall('train_data')\n",
    "        zip_ref.close()\n",
    "        print('unzipping finished')\n",
    "        \n",
    "        X, Y = [], []\n",
    "\n",
    "        for i, row in enumerate(csv.reader(open('train_data/train.csv', encoding='utf8'))):\n",
    "            if i > 0: # Skip the header line\n",
    "                sys.stderr.write('\\r'+str(i))\n",
    "                sys.stderr.flush()\n",
    "                text = re.findall('\\w+', row[1].lower())\n",
    "                if remove_stopwords:\n",
    "                    text = [w for w in text if not w in STOPWORDS]\n",
    "\n",
    "                if remove_numbers:\n",
    "                    text = [w for w in text if not re.sub('\\'\\.,','',w).isdigit()]\n",
    "\n",
    "                if do_stem:\n",
    "                    text = [STEMMER.stem(w) for w in text]\n",
    "\n",
    "                label = 1 if '1' in row[2:] else 0 # Any hate speach label\n",
    "                X.append(' '.join(text))\n",
    "                Y.append(label)\n",
    "\n",
    "        sys.stderr.write('\\n')\n",
    "        pickle.dump(X, open('X.pkl', 'wb'))\n",
    "        pickle.dump(Y, open('Y.pkl', 'wb'))\n",
    "    else:\n",
    "        X = pickle.load(open('X.pkl', 'rb'))\n",
    "        Y = pickle.load(open('Y.pkl', 'rb'))\n",
    "\n",
    "    print(len(X), 'data points read')\n",
    "    print('Label distribution:',Counter(Y))\n",
    "    print('As percentages:')\n",
    "\n",
    "    for label, count_ in Counter(Y).items():\n",
    "        print(label, ':', round(100*(count_/len(X)), 2))\n",
    "        \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159571\n",
      "Vectorizing with TFIDF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571 data points read\n",
      "Label distribution: Counter({0: 143346, 1: 16225})\n",
      "As percentages:\n",
      "0 : 89.83\n",
      "1 : 10.17\n",
      "Data shape: (159571, 1000)\n",
      "Downsampled data shape: (31914, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification and evaluation\n"
     ]
    }
   ],
   "source": [
    "print('Loading data', file=sys.stderr)\n",
    "X, Y = read_data()\n",
    "\n",
    "print('Vectorizing with TFIDF', file=sys.stderr)\n",
    "tfidfizer = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf_matrix = tfidfizer.fit_transform(X)\n",
    "print('Data shape:', X_tfidf_matrix.shape)\n",
    "do_downsample = True\n",
    "\n",
    "if do_downsample: # Only take 20% of the data\n",
    "    X_tfidf_matrix, X_, Y, Y_ = train_test_split(X_tfidf_matrix, Y, test_size=0.8, random_state=42, stratify=Y)\n",
    "    print('Downsampled data shape:', X_tfidf_matrix.shape)\n",
    "\n",
    "print('Classification and evaluation', file=sys.stderr)\n",
    "# Randomly split data into 80% training and 20% testing, preserve class distribution with stratify\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_tfidf_matrix, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0)]\n",
    "\n",
    "CV = 2\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, X_tfidf_matrix, Y, scoring='accuracy', cv=CV)\n",
    "    \n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare models with graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot accurency with graphic\n",
    "\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare models with number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.950429\n",
       "LogisticRegression        0.943692\n",
       "MultinomialNB             0.940841\n",
       "RandomForestClassifier    0.898320\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot accurency with numbers\n",
    "cv_df.groupby('model_name').accuracy.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting data...\n",
      "Predicting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.94      5734\n",
      "          1       0.47      0.78      0.59       649\n",
      "\n",
      "avg / total       0.92      0.89      0.90      6383\n",
      "\n",
      "[[5166  568]\n",
      " [ 144  505]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(class_weight='balanced', C=4.5) # Weight samples inverse to class imbalance\n",
    "# clf = SVC(kernel='rbf', class_weight='balanced', C=4.5) # Weight samples inverse to class imbalance\n",
    "# clf = SVC(class_weight='balanced') # Weight samples inverse to class imbalance\n",
    "\n",
    "print('Fitting data...')\n",
    "if os.path.exists('trained_classifier.pkl'):\n",
    "    with open('trained_classifier.pkl', 'rb') as fid:\n",
    "        clf = pickle.load(fid)\n",
    "else:\n",
    "    clf.fit(X_train, Y_train)\n",
    "    with open('trained_classifier.pkl', 'wb') as fid:\n",
    "        pickle.dump(clf, fid)\n",
    "\n",
    "print('Predicting data...')\n",
    "if os.path.exists('trained_classifier_prediction.pkl'):\n",
    "    with open('trained_classifier_prediction.pkl', 'rb') as fid:\n",
    "        y_pred = pickle.load(fid)\n",
    "else:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    with open('trained_classifier_prediction.pkl', 'wb') as fid:\n",
    "        pickle.dump(y_pred, fid)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, y_pred), file=sys.stderr)\n",
    "print(confusion_matrix(Y_test, y_pred.tolist()), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numcv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b8275d6fd894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tfidf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numcv' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(clf, X_tfidf_matrix, Y, cv=numcv)\n",
    "print(classification_report(Y, y_pred), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
